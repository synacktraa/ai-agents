{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    This notebook goes through the process of building a ReAct agent from scratch.\n",
    "    <br>\n",
    "    <br>\n",
    "    <a href=\"https://colab.research.google.com/github/synacktraa/ai-agents/blob/main/built-from-scratch/ReAct-agent.ipynb\">\n",
    "        <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "    </a>\n",
    "</p>\n",
    "<div style=\"display: flex\">\n",
    "    <h3 style=\"margin: 0;\">Tutorial by James Murdza: </h3>\n",
    "    <a href=\"https://youtu.be/C0QdSBoJiMs\" style=\"margin-left: 10px;\">\n",
    "        <img src=\"https://img.shields.io/badge/YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white\" alt=\"YouTube\">\n",
    "    </a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install \"docstring-parser>=0.16\" duckduckgo-search litellm loguru sympy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing `ReActTool`\n",
    "\n",
    "First, we're going to implement a `ReActTool` class. \n",
    "\n",
    "It will be responsible for:\n",
    "\n",
    "- Wrapping a function that must have exactly one parameter of a supported type (string, integer, float, boolean, list, dictionary, tuple, or set). If no type is specified for the parameter, it will be treated as a string. The function must also include a docstring that describes what it does.\n",
    "\n",
    "- Converting raw string inputs into the correct type before passing them to the wrapped function. For example, if the wrapped function expects an integer, the ReActTool will automatically convert string inputs like \"123\" into the integer 123."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from typing import Any, Callable, Generic, Protocol, TypeVar\n",
    "\n",
    "from docstring_parser import parse\n",
    "\n",
    "\n",
    "T_Param = TypeVar(\"T_Param\", str, int, float, bool, list, dict, tuple, set)\n",
    "\"\"\"Type representing the accepted parameter types for the function.\"\"\"\n",
    "\n",
    "class SupportsStr(Protocol):\n",
    "    def __str__(self) -> str:\n",
    "        ...\n",
    "\n",
    "T_Retval = TypeVar(\"T_Retval\", bound=SupportsStr)\n",
    "\"\"\"Type representing the return value of the function that can be converted to string.\"\"\"\n",
    "\n",
    "\n",
    "def validate_and_get_cast_type(__fn: Callable[..., Any]) -> type:\n",
    "    \"\"\"Validate if the function is compatible with ReAct agent and get the cast type.\"\"\"\n",
    "\n",
    "    if not inspect.isfunction(__fn):\n",
    "        raise TypeError(f\"Expected a function, got {type(__fn)}\")\n",
    "    \n",
    "    fn_params = list(inspect.signature(__fn).parameters.values())\n",
    "    if len(fn_params) != 1:\n",
    "        raise ValueError(f\"Expected a function with a single parameter, got {len(fn_params)}\")\n",
    "    \n",
    "    cast_type = fn_params[0].annotation\n",
    "    if cast_type in (Any, inspect._empty):\n",
    "        return str  # Default to string if any or no type is specified\n",
    "    \n",
    "    if cast_type not in T_Param.__constraints__:\n",
    "        constraints = tuple(map(lambda x: x.__name__, T_Param.__constraints__))\n",
    "        raise ValueError(\n",
    "            f\"Expected a function with one of the following parameter types: {constraints}\"\n",
    "        )\n",
    "    return cast_type\n",
    "        \n",
    "\n",
    "class ReActTool(Generic[T_Param, T_Retval]):\n",
    "    \"\"\"\n",
    "    Class for creating a ReAct agent compatible tool from a function.\n",
    "    \n",
    "    A ReAct agent tool is supposed to be a function that takes a single parameter.\n",
    "    \"\"\"\n",
    "    def __init__(self, __fn: Callable[[T_Param], T_Retval]):\n",
    "\n",
    "        self._cast_type = validate_and_get_cast_type(__fn)\n",
    "        \n",
    "        docstring = parse(__fn.__doc__ or \"\")\n",
    "        if docstring.description is None:\n",
    "            raise ValueError(\"Function must include a description\")\n",
    "        \n",
    "        self.__fn = __fn\n",
    "        self.name = self.__fn.__name__\n",
    "        self.description = docstring.description\n",
    "\n",
    "    def __call__(self, __arg: T_Param) -> T_Retval:\n",
    "        \"\"\"Call the function associated with the adapter.\"\"\"\n",
    "        \n",
    "        return self.__fn(__arg)\n",
    "    \n",
    "    def call_with_action_input(self, input: str) -> T_Retval:\n",
    "        \"\"\"Call the associated function with raw action input.\"\"\"\n",
    "\n",
    "        return self.__fn(self._cast_type(input))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a ReAct agent\n",
    "\n",
    "Before we start with the implementation, let's get a basic understanding of the `ReAct` agent.\n",
    "\n",
    "`ReAct` stands for `Reason` and `Action`. It is a type of agent that processes the user's query in an iterative manner. The agent has access to a set of tools which can be used to solve the query or its sub-problems (when the agent breaks down complex queries during reasoning).\n",
    "\n",
    "The agent processes queries through the following loop:\n",
    "\n",
    "- The agent receives a query and thinks about how to solve it\n",
    "- If a tool is needed, the agent specifies:\n",
    "  - Action: The name of the tool to use\n",
    "  - Action Input: The input to provide to that tool\n",
    "- The specified tool is called and its result becomes an Observation\n",
    "- The agent then either:\n",
    "  - Provides a Final Answer if it has solved the query\n",
    "  - Or continues thinking and using more tools until it reaches a solution\n",
    "- The loop stops when either a Final Answer is provided or no valid action can be taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Logger\n",
    "import sys\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "logger.remove()\n",
    "\n",
    "logger.add(sys.stdout, format=\"<level>{message}</level>\")\n",
    "logger = logger.opt(colors=True)\n",
    "\n",
    "def highlight_role(role: str) -> str:\n",
    "    return f\"<bg #0f0707><fg #ffffff>[{role.upper()}]</fg #ffffff></bg #0f0707>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from string import Template\n",
    "from typing import Callable\n",
    "\n",
    "from litellm import completion as get_completion\n",
    "\n",
    "\n",
    "TOOL_TEMPLATE = Template(\"${name}: ${description}\")\n",
    "\"\"\"Template for tool description.\"\"\"\n",
    "\n",
    "\n",
    "INSTRUCTION_TEMPLATE = Template(\"\"\"\\\n",
    "You can only utilize the following tools to answer the user's query:\n",
    "${tools_representation}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Query: the input query you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of ${tool_names}\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (the Thought/Action/Observation can repeat any number of times)\n",
    "Thought: I now know the final answer!\n",
    "Final Answer: the answer to the original input query\\\n",
    "\"\"\")\n",
    "\"\"\"Instruction template for ReAct agent.\"\"\"\n",
    "\n",
    "\n",
    "class NoResult:\n",
    "    \"\"\"A sentinel value to indicate action or tool is not available.\"\"\"\n",
    "\n",
    "\n",
    "class ReactAgent:\n",
    "    \"\"\"\n",
    "    React agent implementation that uses tools to solve given tasks.\n",
    "    This agent uses litellm to connect with Language Models.\n",
    "    Make sure to set the api key of the provider you are using.\n",
    "    \"\"\"\n",
    "    def __init__(self, *functions: Callable[[T_Param], T_Retval]) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            functions: A list of functions to use as tools for the agent.\n",
    "        \"\"\"\n",
    "\n",
    "        if not functions:\n",
    "            raise ValueError(\"Atleast one function is required.\")\n",
    "\n",
    "        tools_representation = \"\"\n",
    "        self._tool_registry: dict[str, ReActTool] = {}\n",
    "        for fn in functions:  # Add the functions as tools to the registry\n",
    "            tool = ReActTool(fn)\n",
    "            self._tool_registry[tool.name] = tool\n",
    "            tool_repr = TOOL_TEMPLATE.substitute(name=tool.name, description=tool.description)\n",
    "            tools_representation += tool_repr + \"\\n\"\n",
    "        \n",
    "        self.instruction = INSTRUCTION_TEMPLATE.substitute(\n",
    "            tools_representation=tools_representation.strip(),\n",
    "            tool_names=list(self._tool_registry)\n",
    "        )\n",
    "        \"\"\"Instruction for the agent.\"\"\"\n",
    "\n",
    "        # Intialize message history with system instruction\n",
    "        self.__message_history = [{\"role\": \"system\", \"content\": self.instruction}]\n",
    "\n",
    "    def _parse_section(self, text: str, section: str) -> str | None:\n",
    "        \"\"\"Parse the section of the message.\"\"\"\n",
    "        _match = re.search(rf\"{section}: (.*)\", text)\n",
    "        if _match:\n",
    "            return _match.group(1).strip()\n",
    "\n",
    "    def parse_action_and_get_result(self, ai_message: str) -> Any | NoResult:\n",
    "        \"\"\"Parse action and input from AI message and call the corresponding tool.\"\"\"\n",
    "\n",
    "        action = self._parse_section(ai_message, \"Action\")\n",
    "        action_input = self._parse_section(ai_message, \"Action Input\")\n",
    "        if action and action_input:\n",
    "            logger.info(\n",
    "                f\"‚öôÔ∏è Action: {action!r} || ‚å®Ô∏è Input: {action_input!r}\"\n",
    "            )\n",
    "            if tool := self._tool_registry.get(action):\n",
    "                return tool.call_with_action_input(action_input)\n",
    "        \n",
    "        return NoResult    \n",
    "\n",
    "    def process_ai_message(self, content: str) -> bool:\n",
    "        \"\"\"Process an AI message and tell if the agent should continue solving the query.\"\"\"\n",
    "\n",
    "        logger.info(highlight_role(\"self\"))\n",
    "        if thought := self._parse_section(content, \"Thought\"):\n",
    "            logger.info(f\"üí≠ Thought: {thought}\")\n",
    "\n",
    "        # If final answer is there, we tell the agent to stop.\n",
    "        if final := self._parse_section(content, \"Final Answer\"):\n",
    "            logger.info(f\"üìå Final Answer: {final}\")\n",
    "            self.__message_history.append({\"role\": \"assistant\", \"content\": final})\n",
    "            return False\n",
    "        \n",
    "        # Parse ai message and get the action result\n",
    "        action_result = self.parse_action_and_get_result(content)\n",
    "        if action_result is NoResult:\n",
    "            return False\n",
    "        \n",
    "        logger.info(f\"üîé Observation: {str(action_result)}\")\n",
    "        \n",
    "        # Add the ai message and observation to the message history\n",
    "        self.__message_history.extend([\n",
    "            {\"role\": \"assistant\", \"content\": content.strip()},\n",
    "            {\"role\": \"user\", \"content\": f\"Observation: {str(action_result)}\"}\n",
    "        ])\n",
    "        return True\n",
    "\n",
    "    def __call__(self, *, query: str, model: str) -> str:\n",
    "        \"\"\"\n",
    "        Call the agent.\n",
    "\n",
    "        Args:\n",
    "            query: The query to complete\n",
    "            model: The model to use for the agent. Explore models: https://openrouter.ai/models\n",
    "        \"\"\"\n",
    "        query = query.strip()\n",
    "        logger.info(f\"üñãÔ∏è Query: {query}\\n\")\n",
    "\n",
    "        # Add user query to message history\n",
    "        self.__message_history.append({\"role\": \"user\", \"content\": f\"Query: {query}\"})\n",
    "\n",
    "        while True:\n",
    "            # Get response from Open Router client\n",
    "            ai_message = get_completion(\n",
    "                model, self.__message_history, stop=[\"Observation:\"]\n",
    "            ).choices[0].message.content\n",
    "            \n",
    "            # Process the AI message\n",
    "            if not self.process_ai_message(ai_message):\n",
    "                break\n",
    "            \n",
    "            logger.info(\"\")\n",
    "        \n",
    "    @property\n",
    "    def history(self) -> list[dict[str, str]]:\n",
    "        \"\"\"Messasge history\"\"\"\n",
    "        return self.__message_history\n",
    "\n",
    "    def show_history(self) -> None:\n",
    "        \"\"\"Display the message history.\"\"\"\n",
    "        for message in self.__message_history:\n",
    "            logger.info(f\"{highlight_role(message['role'])} \\n{message['content']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining tools and creating a ReAct agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckduckgo_search import DDGS, exceptions\n",
    "from sympy import sympify\n",
    "\n",
    "def search_text(text: str):\n",
    "    \"\"\"Search for text in the web.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        return DDGS().text(keywords=text)\n",
    "    except exceptions.RatelimitException:\n",
    "        return \"Rate limit exceeded. Return final answer.\"\n",
    "    \n",
    "def calulate_math_expression_with_sympy(expression):\n",
    "    \"\"\"Calculate a mathematical expression using sympy.\"\"\"\n",
    "\n",
    "    try:\n",
    "        result = sympify(expression)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error in calculation: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can only utilize the following tools to answer the user's query:\n",
      "search_text: Search for text in the web.\n",
      "calulate_math_expression_with_sympy: Calculate a mathematical expression using sympy.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Query: the input query you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of ['search_text', 'calulate_math_expression_with_sympy']\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (the Thought/Action/Observation can repeat any number of times)\n",
      "Thought: I now know the final answer!\n",
      "Final Answer: the answer to the original input query\n"
     ]
    }
   ],
   "source": [
    "agent = ReactAgent(search_text, calulate_math_expression_with_sympy)\n",
    "print(agent.instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the ReAct agent\n",
    "\n",
    "I am using Groq because it is super fast and has a good free usage limit. Get your own key from [here](https://console.groq.com/keys). If you want to use other models, you can select one from the [LiteLLM providers](https://docs.litellm.ai/docs/providers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1müñãÔ∏è Query: Find some information about smolagents library.\n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[48;2;15;7;7m\u001b[38;2;255;255;255m[SELF]\u001b[0m\u001b[1m\u001b[48;2;15;7;7m\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[1müí≠ Thought: The user is asking for information about the smolagents library, so I need to search for relevant information about it.\u001b[0m\n",
      "\u001b[1m‚öôÔ∏è Action: 'search_text' || ‚å®Ô∏è Input: 'smolagents library'\u001b[0m\n",
      "\u001b[1müîé Observation: [{'title': 'GitHub - huggingface/smolagents: smolagents: a barebones library for ...', 'href': 'https://github.com/huggingface/smolagents', 'body': 'smolagents is a library that enables you to run powerful agents in a few lines of code. It offers: Simplicity: the logic for agents fits in ~thousand lines of code (see agents.py).We kept abstractions to their minimal shape above raw code! üßë\\u200düíª First-class support for Code Agents, i.e. agents that write their actions in code (as opposed to \"agents being used to write code\").'}, {'title': 'Smolagents : Huggingface AI Agent Framework', 'href': 'https://smolagents.org/', 'body': 'smolagents is a minimalist AI agent library developed by the Hugging Face team. It allows developers to create and run powerful AI agents with minimal code. By focusing on simplicity and efficiency, smolagents enables large language models (LLMs) to interact seamlessly with real-world tasks.'}, {'title': 'smolagents - Hugging Face', 'href': 'https://huggingface.co/docs/smolagents/index', 'body': 'smolagents. This library is the simplest framework out there to build powerful agents! By the way, wtf are \"agents\"? We provide our definition in this page, where you\\'ll also find tips for when to use them or not (spoilers: you\\'ll often be better off without agents).. This library offers:'}, {'title': 'Introduction to Agents - Hugging Face', 'href': 'https://huggingface.co/docs/smolagents/conceptual_guides/intro_agents', 'body': 'smolagents documentation Introduction to Agents. smolagents Search documentation. Get started. ü§ó Agents Guided tour. Tutorials. Building good agents üõ†Ô∏è Tools - in-depth guide üõ°Ô∏è Secure your code execution with E2B. Conceptual guides. ü§ñ An introduction to agentic systems ü§î How do Multi-step agents work? ...'}, {'title': 'Introducing smolagents: A Lightweight Library for Building ... - Medium', 'href': 'https://medium.com/thedeephub/introducing-smolagents-a-lightweight-library-for-building-powerful-agents-a8791a60b5b1', 'body': 'smolagents is an open-source project backed by Hugging Face, fostering a community of contributors and users. The library integrates seamlessly with the Hugging Face Hub, allowing you to share and ...'}, {'title': 'Agents - Guided tour - Hugging Face', 'href': 'https://huggingface.co/docs/smolagents/guided_tour', 'body': 'The system prompt includes: An introduction that explains how the agent should behave and what tools are.; A description of all the tools that is defined by a {{tool_descriptions}} token that is dynamically replaced at runtime with the tools defined/chosen by the user.. The tool description comes from the tool attributes, name, description, inputs and output_type, and a simple jinja2 template ...'}, {'title': 'Hugging Face Smolagents is a Simple Library to Build LLM ... - InfoQ', 'href': 'https://www.infoq.com/news/2025/01/hugging-face-smolagents-agents/', 'body': 'Smolagents is a library created at Hugging Face to build agents based on large language models (LLMs). Hugging Faces says its new library aims to be simple and LLM-agnostic. It supports secure ...'}, {'title': 'Install and Run Powerful smolagents library and AI Agents by Using ...', 'href': 'https://aleksandarhaber.com/install-and-run-powerful-smolagents-library-and-ai-agents-by-using-ollama-and-llama/', 'body': 'Instead, we will explain how to install and use smolagents library \"locally\" by using Ollama and Llama 3.2B. Once you learn how to install smolagents and run test examples, you can proceed further and learn how to develop your own AI agents. You can also use the ideas presented in this tutorial to run any other Large Language Model (LLM ...'}, {'title': 'Hugging Face Just Released SmolAgents: A Smol Library that Enables to ...', 'href': 'https://www.marktechpost.com/2024/12/30/hugging-face-just-released-smolagents-a-smol-library-that-enables-to-run-powerful-ai-agents-in-a-few-lines-of-code/', 'body': \"Understanding Language: SmolAgents taps into advanced NLP models to understand commands and queries. Smart Searching: It connects to external data sources to deliver fast, accurate results. Running Code on the Fly: The agents can dynamically generate and execute code snippets tailored to specific tasks. The toolkit's modular design means it can adapt to various needs, from rapid prototyping ...\"}, {'title': 'Introduction to Smolagents: A Hugging Face Agentic Framework', 'href': 'https://medium.com/@mauryaanoop3/introduction-to-smolagents-a-hugging-face-agentic-framework-190169b424f4', 'body': 'What Are Smolagents? Smolagents is a minimalist yet powerful library that enables the construction of AI agents with minimal code. By providing a simplified interface, it allows developers to ...'}]\u001b[0m\n",
      "\u001b[1m\u001b[0m\n",
      "\u001b[1m\u001b[48;2;15;7;7m\u001b[38;2;255;255;255m[SELF]\u001b[0m\u001b[1m\u001b[48;2;15;7;7m\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[1müí≠ Thought: I have found several sources of information about the smolagents library, including its GitHub page, the Hugging Face website, and various articles and tutorials. I can now summarize the key points about the library.\u001b[0m\n",
      "\u001b[1müìå Final Answer: The smolagents library is a minimalist AI agent library that enables developers to create and run powerful AI agents with minimal code. It offers simplicity, first-class support for Code Agents, and seamless interaction with real-world tasks, and integrates with the Hugging Face Hub.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "def set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass(f\"{var}: \")\n",
    "\n",
    "set_env(\"GROQ_API_KEY\")  # Replace with your LLM compatible environment key.\n",
    "\n",
    "agent(\n",
    "    query=\"Find some information about smolagents library.\", \n",
    "    model=\"groq/llama-3.3-70b-versatile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1müñãÔ∏è Query: Calculate square root of 144.\n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[48;2;15;7;7m\u001b[38;2;255;255;255m[SELF]\u001b[0m\u001b[1m\u001b[48;2;15;7;7m\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[1müí≠ Thought: To calculate the square root of 144, I can use the sympy library, which has a function to calculate square roots.\u001b[0m\n",
      "\u001b[1m‚öôÔ∏è Action: 'calulate_math_expression_with_sympy' || ‚å®Ô∏è Input: 'sqrt(144)'\u001b[0m\n",
      "\u001b[1müîé Observation: 12\u001b[0m\n",
      "\u001b[1m\u001b[0m\n",
      "\u001b[1m\u001b[48;2;15;7;7m\u001b[38;2;255;255;255m[SELF]\u001b[0m\u001b[1m\u001b[48;2;15;7;7m\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[1müí≠ Thought: I now know the final answer!\u001b[0m\n",
      "\u001b[1müìå Final Answer: 12\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent(\n",
    "    query=\"Calculate square root of 144.\", model=\"groq/llama-3.3-70b-versatile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[48;2;15;7;7m\u001b[38;2;255;255;255m[SYSTEM]\u001b[0m\u001b[1m\u001b[48;2;15;7;7m\u001b[0m\u001b[1m \n",
      "You can only utilize the following tools to answer the user's query:\n",
      "search_text: Search for text in the web.\n",
      "calulate_math_expression_with_sympy: Calculate a mathematical expression using sympy.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Query: the input query you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of ['search_text', 'calulate_math_expression_with_sympy']\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (the Thought/Action/Observation can repeat any number of times)\n",
      "Thought: I now know the final answer!\n",
      "Final Answer: the answer to the original input query\n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[48;2;15;7;7m\u001b[38;2;255;255;255m[USER]\u001b[0m\u001b[1m\u001b[48;2;15;7;7m\u001b[0m\u001b[1m \n",
      "Query: Find some information about smolagents library.\n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[48;2;15;7;7m\u001b[38;2;255;255;255m[ASSISTANT]\u001b[0m\u001b[1m\u001b[48;2;15;7;7m\u001b[0m\u001b[1m \n",
      "Thought: The user is asking for information about the smolagents library, so I need to search for relevant information about it.\n",
      "Action: search_text\n",
      "Action Input: smolagents library\n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[48;2;15;7;7m\u001b[38;2;255;255;255m[USER]\u001b[0m\u001b[1m\u001b[48;2;15;7;7m\u001b[0m\u001b[1m \n",
      "Observation: [{'title': 'GitHub - huggingface/smolagents: smolagents: a barebones library for ...', 'href': 'https://github.com/huggingface/smolagents', 'body': 'smolagents is a library that enables you to run powerful agents in a few lines of code. It offers: Simplicity: the logic for agents fits in ~thousand lines of code (see agents.py).We kept abstractions to their minimal shape above raw code! üßë\\u200düíª First-class support for Code Agents, i.e. agents that write their actions in code (as opposed to \"agents being used to write code\").'}, {'title': 'Smolagents : Huggingface AI Agent Framework', 'href': 'https://smolagents.org/', 'body': 'smolagents is a minimalist AI agent library developed by the Hugging Face team. It allows developers to create and run powerful AI agents with minimal code. By focusing on simplicity and efficiency, smolagents enables large language models (LLMs) to interact seamlessly with real-world tasks.'}, {'title': 'smolagents - Hugging Face', 'href': 'https://huggingface.co/docs/smolagents/index', 'body': 'smolagents. This library is the simplest framework out there to build powerful agents! By the way, wtf are \"agents\"? We provide our definition in this page, where you\\'ll also find tips for when to use them or not (spoilers: you\\'ll often be better off without agents).. This library offers:'}, {'title': 'Introduction to Agents - Hugging Face', 'href': 'https://huggingface.co/docs/smolagents/conceptual_guides/intro_agents', 'body': 'smolagents documentation Introduction to Agents. smolagents Search documentation. Get started. ü§ó Agents Guided tour. Tutorials. Building good agents üõ†Ô∏è Tools - in-depth guide üõ°Ô∏è Secure your code execution with E2B. Conceptual guides. ü§ñ An introduction to agentic systems ü§î How do Multi-step agents work? ...'}, {'title': 'Introducing smolagents: A Lightweight Library for Building ... - Medium', 'href': 'https://medium.com/thedeephub/introducing-smolagents-a-lightweight-library-for-building-powerful-agents-a8791a60b5b1', 'body': 'smolagents is an open-source project backed by Hugging Face, fostering a community of contributors and users. The library integrates seamlessly with the Hugging Face Hub, allowing you to share and ...'}, {'title': 'Agents - Guided tour - Hugging Face', 'href': 'https://huggingface.co/docs/smolagents/guided_tour', 'body': 'The system prompt includes: An introduction that explains how the agent should behave and what tools are.; A description of all the tools that is defined by a {{tool_descriptions}} token that is dynamically replaced at runtime with the tools defined/chosen by the user.. The tool description comes from the tool attributes, name, description, inputs and output_type, and a simple jinja2 template ...'}, {'title': 'Hugging Face Smolagents is a Simple Library to Build LLM ... - InfoQ', 'href': 'https://www.infoq.com/news/2025/01/hugging-face-smolagents-agents/', 'body': 'Smolagents is a library created at Hugging Face to build agents based on large language models (LLMs). Hugging Faces says its new library aims to be simple and LLM-agnostic. It supports secure ...'}, {'title': 'Install and Run Powerful smolagents library and AI Agents by Using ...', 'href': 'https://aleksandarhaber.com/install-and-run-powerful-smolagents-library-and-ai-agents-by-using-ollama-and-llama/', 'body': 'Instead, we will explain how to install and use smolagents library \"locally\" by using Ollama and Llama 3.2B. Once you learn how to install smolagents and run test examples, you can proceed further and learn how to develop your own AI agents. You can also use the ideas presented in this tutorial to run any other Large Language Model (LLM ...'}, {'title': 'Hugging Face Just Released SmolAgents: A Smol Library that Enables to ...', 'href': 'https://www.marktechpost.com/2024/12/30/hugging-face-just-released-smolagents-a-smol-library-that-enables-to-run-powerful-ai-agents-in-a-few-lines-of-code/', 'body': \"Understanding Language: SmolAgents taps into advanced NLP models to understand commands and queries. Smart Searching: It connects to external data sources to deliver fast, accurate results. Running Code on the Fly: The agents can dynamically generate and execute code snippets tailored to specific tasks. The toolkit's modular design means it can adapt to various needs, from rapid prototyping ...\"}, {'title': 'Introduction to Smolagents: A Hugging Face Agentic Framework', 'href': 'https://medium.com/@mauryaanoop3/introduction-to-smolagents-a-hugging-face-agentic-framework-190169b424f4', 'body': 'What Are Smolagents? Smolagents is a minimalist yet powerful library that enables the construction of AI agents with minimal code. By providing a simplified interface, it allows developers to ...'}]\n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[48;2;15;7;7m\u001b[38;2;255;255;255m[ASSISTANT]\u001b[0m\u001b[1m\u001b[48;2;15;7;7m\u001b[0m\u001b[1m \n",
      "The smolagents library is a minimalist AI agent library that enables developers to create and run powerful AI agents with minimal code. It offers simplicity, first-class support for Code Agents, and seamless interaction with real-world tasks, and integrates with the Hugging Face Hub.\n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[48;2;15;7;7m\u001b[38;2;255;255;255m[USER]\u001b[0m\u001b[1m\u001b[48;2;15;7;7m\u001b[0m\u001b[1m \n",
      "Query: Calculate square root of 144.\n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[48;2;15;7;7m\u001b[38;2;255;255;255m[ASSISTANT]\u001b[0m\u001b[1m\u001b[48;2;15;7;7m\u001b[0m\u001b[1m \n",
      "Thought: To calculate the square root of 144, I can use the sympy library, which has a function to calculate square roots.\n",
      "Action: calulate_math_expression_with_sympy\n",
      "Action Input: sqrt(144)\n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[48;2;15;7;7m\u001b[38;2;255;255;255m[USER]\u001b[0m\u001b[1m\u001b[48;2;15;7;7m\u001b[0m\u001b[1m \n",
      "Observation: 12\n",
      "\u001b[0m\n",
      "\u001b[1m\u001b[48;2;15;7;7m\u001b[38;2;255;255;255m[ASSISTANT]\u001b[0m\u001b[1m\u001b[48;2;15;7;7m\u001b[0m\u001b[1m \n",
      "12\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent.show_history()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
